{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7aAfRmRTWP5T"},"outputs":[],"source":["from fastai.vision.all import *\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":342,"referenced_widgets":["01d8a00a3232451da8a07e5badf1809e"]},"executionInfo":{"elapsed":223641,"status":"ok","timestamp":1662362642948,"user":{"displayName":"bong bong","userId":"17774416216702601338"},"user_tz":-540},"id":"S1PGau_oIjxz","outputId":"bb839eeb-b4e6-4db8-bb29-a98d67210fd9"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/fastai/vision/learner.py:284: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n","  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"01d8a00a3232451da8a07e5badf1809e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/83.3M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>error_rate</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.151478</td>\n","      <td>0.019330</td>\n","      <td>0.006089</td>\n","      <td>32:29</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      0.00% [0/1 00:00&lt;?]\n","    </div>\n","    \n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>error_rate</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>\n","\n","    <div>\n","      <progress value='57' class='' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      61.96% [57/92 27:13&lt;16:42 0.0485]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["path = untar_data(URLs.PETS)/'images'\n","def is_cat(x):\n","    return x[0].isupper()\n","dls = ImageDataLoaders.from_name_func(path, get_image_files(path),valid_pct = 0.2, seed=21,\n","                                      label_func = is_cat, item_tfms = Resize(224))\n","learn = cnn_learner(dls, resnet34, metrics = error_rate)\n","learn.fine_tune(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":190},"executionInfo":{"elapsed":22,"status":"error","timestamp":1662362642949,"user":{"displayName":"bong bong","userId":"17774416216702601338"},"user_tz":-540},"id":"EeyCeTXEgpId","outputId":"6b47e758-a067-42f0-b2fb-a4f48da0d3d9"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-f6315c888e9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPILImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_cat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'image_cat' is not defined"]}],"source":["img = PILImage.create(image_cat())\n","x, = first(dls.test_dl([img]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q0CkLS2NgPu3"},"outputs":[],"source":["class Hook():\n","    def hook_func(self, m, i, o):\n","        self.stored = o.detch().clone()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7PIzH4NCgYSJ"},"outputs":[],"source":["hook_output = Hook()\n","hook = learn.model[0].register_forward_hook(hook_output.hook_func)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PMiO4NUighQl"},"outputs":[],"source":["with torch.no_grad():\n","    output = learn.model.eval()(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5wx-1O05g3Nb"},"outputs":[],"source":["act = hook_output.stored[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bS0O5M3tg7Aa"},"outputs":[],"source":["F.softmax(output, dim = -1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jrephe_Tg9xU"},"outputs":[],"source":["dls.vocab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l4qxhjW-hmHu"},"outputs":[],"source":["act.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WplH9cxdhm3i"},"outputs":[],"source":["cam_map = torch.einsum('ck, kij->cij', learn.model[1][-1].weight, act)\n","cam_map.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"muE1JkvAhvQj"},"outputs":[],"source":["x_dec = TensorImage(dls.train.decode((x,)[0][0]))\n","_,ax = plt.subplots()\n","x_dec.show(ctx = ax)\n","ax.image(cam_map[1].detach().cpu(), alpha = .6, extent = (0, 224,224,0), interpolation = 'bilinear', cmap='magma')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mXvQcLRdiA5P"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMnh4MpYUDdVNbUoZl2L+Lo"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{}}},"nbformat":4,"nbformat_minor":0}